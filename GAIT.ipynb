{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "GAIT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiGc6KFqTB_D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79311aec-c224-42f5-bc5b-95b48a19deea"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.utils import np_utils\n",
        "import tensorflow\n",
        "import matplotlib.pyplot as plt\n",
        "#import cv2\n",
        "#import glob\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY2dLLT5zrN0"
      },
      "source": [
        "rootDir = r\"D:\\csia dataset\\_\\CASIA-Dataset-A\\silhouettes\"\n",
        "\n",
        "users = os.listdir(rootDir)\n",
        "\n",
        "user_path = []\n",
        "for i in users:\n",
        "    i = rootDir + \"\\\\\" + i\n",
        "    user_path.append(i)\n",
        "\n",
        "user_path = []\n",
        "for i in users:\n",
        "    i = rootDir + \"\\\\\" + i\n",
        "    user_path.append(i)\n",
        "train_set = []\n",
        "validation_set = []\n",
        "test_set = []\n",
        "\n",
        "for user in user_path:\n",
        "    path = os.listdir(user)\n",
        "    for num in path:\n",
        "        if num[-1] == \"1\" or num[-1] == \"2\":\n",
        "            train_set.append(user + \"\\\\\" + num)\n",
        "        if num[-1] == \"3\":\n",
        "            validation_set.append(user + \"\\\\\" + num)  \n",
        "        if num[-1] == \"4\":\n",
        "            test_set.append(user + \"\\\\\" + num)\n",
        "            \n",
        "\n",
        "training_path = []\n",
        "for item in train_set:\n",
        "    images = os.listdir(item)\n",
        "    for img in images:\n",
        "        training_path.append(item + \"\\\\\" + img)\n",
        "testing_path = []\n",
        "for item in test_set:\n",
        "    images = os.listdir(item)\n",
        "    for img in images:\n",
        "        testing_path.append(item + \"\\\\\" + img)\n",
        "validation_path = []\n",
        "for item in validation_set:\n",
        "    images = os.listdir(item)\n",
        "    for img in images:\n",
        "        validation_path.append(item + \"\\\\\" + img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id6_RnfFzuvZ"
      },
      "source": [
        "def make_label(img_path):\n",
        "    label_list = []\n",
        "    for path in img_path:\n",
        "        label = (path[46:49])\n",
        "        label_list.append(label)\n",
        "    return label_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtzl_P1czxKd"
      },
      "source": [
        "y_col = make_label(training_path)\n",
        "data = pd.DataFrame(list(zip(training_path, y_col)), columns = [\"x_col\", \"y_col\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8RMkwITTB_b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "09e4616d-9223-482e-acc5-b13bf0465c19"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                \n",
        "                shear_range = 0.2,\n",
        "                zoom_range = 0.2,\n",
        "                horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "                r\"D:\\csia dataset\\_\\CASIA-Dataset-A\\silhouettes\",\n",
        "                target_size = (64,64),\n",
        "                batch_size = 32,\n",
        "                class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "                r\"D:\\csia dataset\\_\\CASIA-Dataset-A\\silhouettes\",\n",
        "                target_size = (64,64),\n",
        "                batch_size = 32,\n",
        "                class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b3304bcba493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 class_mode = 'categorical')\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m test_set = test_datagen.flow_from_directory(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             dtype=dtype)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\csia dataset\\\\_\\\\CASIA-Dataset-A\\\\silhouettes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "jclGgctfTB_p",
        "outputId": "f436f498-ea14-4600-c7d3-8635daf473ac"
      },
      "source": [
        "print(test_set.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DirectoryIterator' object has no attribute 'shape'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-17-04860c92fe76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SzW7EDgTB_8",
        "outputId": "b9516b26-77f6-4fca-e9a8-a984184bb910"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32,(3,3), activation='relu', input_shape=(64,64,3)))\n",
        "model.add(Convolution2D(64,(3,3), activation='relu'))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Convolution2D(32,(5,5), activation = 'relu'))\n",
        "model.add(Convolution2D(8,(5,5), activation = 'relu'))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(20, activation = 'softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 60, 60, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 60, 60, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 32)        51232     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 22, 22, 8)         6408      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3872)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                77460     \n",
            "=================================================================\n",
            "Total params: 154,492\n",
            "Trainable params: 154,492\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_TJsH_JTCAH",
        "outputId": "d724370a-5088-4544-d2db-0042096170d1"
      },
      "source": [
        "hist = model.fit_generator(training_set, epochs = 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "598/598 [==============================] - 272s 455ms/step - loss: 0.1572 - accuracy: 0.9522\n",
            "Epoch 2/20\n",
            "598/598 [==============================] - 271s 452ms/step - loss: 0.1175 - accuracy: 0.9592\n",
            "Epoch 3/20\n",
            "598/598 [==============================] - 265s 443ms/step - loss: 0.0959 - accuracy: 0.9659\n",
            "Epoch 4/20\n",
            "598/598 [==============================] - 279s 466ms/step - loss: 0.0844 - accuracy: 0.9692\n",
            "Epoch 5/20\n",
            "598/598 [==============================] - 319s 533ms/step - loss: 0.0777 - accuracy: 0.9713\n",
            "Epoch 6/20\n",
            "598/598 [==============================] - 290s 484ms/step - loss: 0.0736 - accuracy: 0.9723\n",
            "Epoch 7/20\n",
            "598/598 [==============================] - 285s 477ms/step - loss: 0.0701 - accuracy: 0.9739\n",
            "Epoch 8/20\n",
            "581/598 [============================>.] - ETA: 7s - loss: 0.0676 - accuracy: 0.9744"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxI_cKy0TCAS"
      },
      "source": [
        "# plt.figure(0)\n",
        "# plt.plot(hist.history['loss'], 'g')\n",
        "# plt.plot(hist.history['val_loss'], 'b')\n",
        "\n",
        "# plt.plot(hist.history['accuracy'],'r')\n",
        "# plt.plot(hist.history['val_acc'], 'black')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvFLXSStTCAe"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img(r'C:\\Users\\Divij\\Desktop\\dog.jpg', target_size = (64,64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)\n",
        "training_set.class_indices\n",
        "\n",
        "if result[0][0] >=0.5:\n",
        "    prediction = 'Person 1'\n",
        "else:\n",
        "    prediction = 'Person 2'\n",
        "print(prediction)\n",
        "\n",
        "\n",
        "print(result[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}